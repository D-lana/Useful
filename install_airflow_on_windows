Устанавливаем WSL2

Заходим в терминал wsl и выполняем следующие команды
sudo apt-get update
sudo apt-get install build-essential python3-dev libpq-dev

Создаем виртуальное окружение и активируем его:
sudo apt-get install python3-venv
python3 -m venv .venv
source .venv/bin/activate

Обновляем pip:
pip install pip -U


Установка как в документации: https://airflow.apache.org/docs/apache-airflow/stable/installation/installing-from-pypi.html
pip install "apache-airflow[postgres]==2.10.4" --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-2.10.4/constraints-3.8.txt"


export AIRFLOW_HOME=~/airflow-data

Установка базы данных postgresql:
sudo apt update
sudo apt install postgresql postgresql-contrib
Заходим в Postgres:
sudo -u postgres psql

Из офф документации https://airflow.apache.org/docs/apache-airflow/stable/howto/set-up-database.html#database-uri
Создаем БД и юзера для airflow:
CREATE DATABASE airflow_db;
CREATE USER airflow_user WITH PASSWORD 'airflow_pass';
GRANT ALL PRIVILEGES ON DATABASE airflow_db TO airflow_user;
GRANT ALL ON SCHEMA public TO airflow_user;
\q


Отредактировать конфиг airflow:
cd airflow-data
nano airflow.cfg

Заменить путь к дагам на:
dags_folder = /mnt/c/Dlana/docker_airflow/dags

Отключить загрузку примеров дагов:
load_examples = False

Изменить executor с:
executor = SequentialExecutor
на:
executor = LocalExecutor

Изменить базу данных с sqlite:
sql_alchemy_conn = sqlite:////home/margarita/airflow-data/airflow.db
на postgresql+psycopg2:
sql_alchemy_conn = postgresql+psycopg2://airflow_user:airflow_pass@localhost/airflow_db

проверить соединение к БД:
psql -U airflow_user -h localhost -d airflow_db

создаем юзера:
airflow users create \
--username airflow \
--firstname Margarita \
--lastname K \
--role Admin \
--email email@example.com \
--password airflow

Запускаем вебсервер:
airflow webserver -p 8080


Открываем второй терминал wsl и запускаем шедулер:
source .venv/bin/activate
export AIRFLOW_HOME=~/airflow-data
airflow scheduler




